= Set
:navtitle: Set
:description: 

{description}

A `Set` is a `Collection` that 
    
1. **that cannot contain duplicates**; 
2. **adding an item if it is already present in the set has no effect**. 

* It models the mathematical set abstraction. 

* The Set interface contains only methods inherited from `Collection` and **adds the restriction that duplicate elements are prohibited**. `Set` also adds a stronger contract on the behavior of the `equals` and `hashCode` operations, allowing `Set` instances to be compared meaningfully even if their implementation types differ. 

* Two Set instances are equal if they contain the same elements.

---

== Set Interface Basic Operations:

* `size` operation returns the number of elements in the `Set` (its cardinality). 
* `isEmpty` method checks if collection is empty. 
* `add` method adds the specified element to the `Set` if it is not already present and returns a boolean indicating whether the element was added. 
* `remove` method removes the specified element from the `Set` if it is present and returns a boolean indicating whether the element was present. 
* `iterator` method returns an `Iterator` over the `Set`.


**Using JDK 8 Aggregate Operations:**

```
import java.util.*;
import java.util.stream.*;

public class FindDups {
    public static void main(String[] args) {
        Set<String> distinctWords = Arrays.asList(args).stream()
		.collect(Collectors.toSet()); 
        System.out.println(distinctWords.size()+ 
                           " distinct words: " + 
                           distinctWords);
    }
}
```
**Using the `for-each` Construct:**

```
import java.util.*;

public class FindDups {
    public static void main(String[] args) {
        Set<String> s = new HashSet<String>();
        for (String a : args)
               s.add(a);
        System.out.println(s.size() + " distinct words: " + s);
    }
}
```
---

== Set Interface Bulk Operations:

**Bulk operations are particularly well suited to** `Sets`; when applied, they perform standard set-algebraic operations. 

Suppose s1 and s2 are sets. Here's what bulk operations do:

* `s1.containsAll(s2)` — returns `true` if s2 is a **subset** of s1. (s2 is a subset of s1 if set s1 contains all of the elements in s2.)
* `s1.addAll(s2)` — transforms s1 into the **union** of s1 and s2. (The union of two sets is the set containing all of the elements contained in either set.)
* `s1.retainAll(s2)` — transforms s1 into the **intersection** of s1 and s2. (The intersection of two sets is the set containing only the elements common to both sets.)
* `s1.removeAll(s2)` — transforms s1 into the **(asymmetric) set difference** of s1 and s2. (For example, the set difference of s1 minus s2 is the set containing all of the elements found in s1 but not in s2.)
  
---

== Set Interface Array Operations
The array operations don't do anything special for `Sets` beyond what they do for any other Collection.

---
== Implementing Set

There are **six concrete implementations** of `Set` in the Collections Framework. 

image::collections/sets_image_1.png[Implementation of Set Interface]

---

=== HashSet

* This class is the most commonly used implementation of `Set`. 
* It is implemented by a hash table, an array in which elements are stored at a position derived from their contents. Since hash tables store and retrieve elements by their content, they are well suited to implementing the operations of `Set`.

[IMPORTANT]
====
* An element’s position in a hash table is calculated by a **hash function** of its contents. Hash functions are designed to give, as far as possible, an even spread of results (hash codes) over the element values that might be stored. 

* Traditionally, hash tables obtain an index from the hash code by taking the remainder after division by the table length. The Collections Framework classes actually use bit masking rather than division. 

* Unless table has more locations than there are values that might be stored in it, sometimes two distinct values must hash to the same location in the hash table. For instance, no int-indexed table can be large enough to store all string values without **collisions**.

* It can minimize the problem with a **good hash function** — one which spreads the elements out equally in the table—but, when collisions do occur, we have to have a way of keeping the colliding elements at the same table location or bucket. 

* This is **often done by storing them in a linked list.**

* it’s enough to see that elements stored at the same bucket can still be accessed, at the cost of following a chain of cell references.
====

```
Set<Character> s1 = new HashSet<Character>(8);
s1.add('a');
s1.add('b');
s1.add('j');
```
image::collections/sets_image_2.png[Hash table with chained overflow]

[NOTE]
====
* As long as there are **no collisions**, the **cost of inserting or retrieving an element is constant.** 
* As the hash table fills, collisions become more likely; assuming a good hash function, the probability of a collision in a lightly loaded table is proportional to its load, defined as the number of elements in the table divided by its capacity (the number of buckets). 
* If a collision does take place, a **linked list has to be created and subsequently traversed**, **adding an extra cost to insertion proportional to the number of elements in the list**. 
* If the size of the hash table is fixed, performance will worsen as more elements are added and the load increases. 
* To prevent this from happening, the table size is increased by rehashing—copying to a new and larger table—when the load reaches a specified threshold (its load factor).

* Iterating over a hash table requires each bucket to be examined to see whether it is occupied and therefore costs a time proportional to the capacity of the hash table plus the number of elements it contains. 
  
* Since the iterator examines each bucket in turn, the order in which elements are returned depends on their hash codes, so there is no guarantee as to the order in which the elements will be returned. 
====

==== Importance

* The chief attraction of a hash table implementation for `sets` is the **constant-time performance** for the basic operations of `add`, `remove`, `contains`, and `size`. 
* Its main **disadvantage** is its **iteration performance**; since iterating through the table involves examining every bucket, its cost is proportional to the table size regardless of the size of the set it contains.
* `HashSet` is **unsychronized** and **not thread-safe**; its **iterators are fail-fast**.

`HashSet` has the standard constructors:

```
HashSet(int initialCapacity)
HashSet(int initialCapacity, float loadFactor)
```

---
=== LinkedHashSet

* This class inherits from `HashSet`, still implementing `Set` **and refining the contract of its superclass in only one respect**: 
* **it guarantees that its iterators will return their elements in the order in which they were first added. It does this by maintaining a linked list of the set elements**

```
Set<Character> s2 = new LinkedHashSet<Character>(8);
Collections.addAll(s2, 'a', 'b', 'j');
// iterators of a LinkedHashSet return their elements in proper order:
assert s2.toString().equals("[a, b, j]");
```
==== Importance

* The linked structure also has a useful consequence in terms of improved performance for iteration: `next` performs in constant time, as the linked list can be used to visit each element in turn. 
* **This is in contrast to `HashSet`**, for which every bucket in the hash table must be visited whether it is occupied or not, 
* but the **overhead involved in maintaining the linked list means that you would choose `LinkedHashSet` in preference to `HashSet` only if the orde or the efficiency of iteration were important for your application.**

* `LinkedHashSet` is **unsychronized** and **not thread-safe**; its **iterators are fail-fast**.

---

=== CopyOnWriteArraySet:

* `CopyOnWriteArraySet` is another straightforward implementation of the `Set` contract, but with quite different performance characteristics from `HashSet`. 

* **This class is implemented as a thin wrapper around an instance of `CopyOnWriteArrayList`, which in turn is backed by an array.**

* **This array is treated as immutable; a change to the contents of the set results in an entirely new array being created**. 

* `add` and `contains` has **complexity O(n)**, which has to be implemented by a linear search.
  
*  Clearly we wouldn’t use `CopyOnWriteArraySet` in a context where we are expecting many searches or insertions. 
*  The **array implementation means that iteration costs O(1) per element** 
   * **faster than `HashSet`** and
   * it **provides thread safety** without adding to the cost of read operations. 
   * **read operations on copy-on-write collections are implemented on the backing array, which is never modified after its creation.**

* `Iterators` for `CopyOnWriteArraySet` **can be used only to read the set**. When they are created, they are attached to the instance of the backing array being used by the set at that moment. 
* **Since no instance of this array should ever be modified, the iterators’ remove method is not implemented.** These are snapshot iterators and they reflect the state of the set at the time they were created, and can subsequently be traversed without any danger of interference from threads modifying the set from which they were derived.

==== Importance

* one that is quite common usages of this is in the implementation of the **[Subject-Observer design pattern](needToAdd)**, which **requires events to be notified to a set of observers**. 
* This `set` must not be modified during the process of notification; with locking set implementations, read and write operations share the overhead necessary to ensure this, whereas with `CopyOnWriteArraySet` the overhead is carried entirely by write operations.

---

=== EnumSet

* This class exists to take advantage of the **efficient implementations that are possible when the number of possible elements is fixed and a unique index can be assigned to each**. 

* These two conditions hold for a set of elements of the same `Enum`
    1. the number of keys is fixed by the constants of the enumerated type, and 
    2. the `ordinal` method returns values that are guaranteed to be unique to each constant. 
    3. The values that `ordinal` returns form a compact range, starting from zero—ideal.

* `add`, `remove`, and `contains` are implemented as **bit manipulations**, with constant-time performance. Bit manipulation on a single word is extremely fast, and a long value can be used to represent `EnumSets` over `enum` types with up to 64 values.

* `EnumSet` is an abstract class that implements these different representations by means of different package-private subclasses. 
* It **hides the concrete implementation from the programmer**, instead exposing [factory methods](needToAdddd) that call the constructor for the appropriate subclass.

```
<E extends Enum<E>> EnumSet<E> of(E first, E... rest)
        // create a set initially containing the specified elements

<E extends Enum<E>> EnumSet<E> range(E from, E to)
        // create a set initially containing all of the elements in
        // the range defined by the two specified endpoints

<E extends Enum<E>> EnumSet<E> allOf(Class<E> elementType)
        // create a set initially containing all elements in elementType

<E extends Enum<E>> EnumSet<E> noneOf(Class<E> elementType)
        // create a set of elementType, initially empty
```        
* An `EnumSet` contains the reified type of its elements, which is used at run time for checking the validity of new entries. This type is supplied by the above factory methods in two different ways. The methods `of` and `range` receive at least one enum argument, which can be queried for its declaring class. 
* For `allOf` and `noneOf`, which have no enum arguments, a class token is supplied instead.

* Common cases for `EnumSet` creation are optimized by the second group of methods, which allow to efficiently create `sets` with one, two, three, four, or five elements of an enumerated type.

```

<E extends Enum<E>> EnumSet<E> of(E e)
<E extends Enum<E>> EnumSet<E> of(E e1, E e2)
<E extends Enum<E>> EnumSet<E> of(E e1, E e2, E e3)
<E extends Enum<E>> EnumSet<E> of(E e1, E e2, E e3, E e4)
<E extends Enum<E>> EnumSet<E> of(E e1, E e2, E e3, E e4, E e5)


```
The third set of methods allows the creation of an EnumSet from an existing collection:

```
<E extends Enum<E>> EnumSet<E> copyOf(EnumSet<E> s)
      // create an EnumSet with the same element type as s, and
      // with the same elements
<E extends Enum<E>> EnumSet<E> copyOf(Collection<E> c)
      // create an EnumSet from the elements of c, which must contain
      // at least one element
<E extends Enum<E>> EnumSet<E> complementOf(EnumSet<E> s)
      // create an EnumSet with the same element type as s,
      // containing the elements not in s

```

The collection supplied as the argument to the second version of copyOf must be nonempty so that the element type can be determined.

* `EnumSet` obeys the **contract for `Set`**, with the added specification **that its iterators will return their elements in their natural order** (the order in which their enum constants are declared). 
* It is **not thread-safe**, but unlike the **unsynchronized** general-purpose collections, its **iterators are not fail-fast**. 
  

---

=== SortedSet:

* `Set` has **one subinterface**, `SortedSet`, which adds to the `Set` contract **a guarantee that maintains its elements in ascending order, sorted according to the elements' natural ordering or according to a `Comparator` provided at `SortedSet` creation time.** 

```
public interface SortedSet<E> extends Set<E> {
    // Range-view
    SortedSet<E> subSet(E fromElement, E toElement);
    SortedSet<E> headSet(E toElement);
    SortedSet<E> tailSet(E fromElement);

    // Endpoints
    E first();
    E last();

    // Comparator access
    Comparator<? super E> comparator();
}

```

* `SortedSet` was itself extended in Java 6 by the interface `NavigableSet`, **which adds methods to find the closest matches to a target element**. 
  
* The only implementation of `SortedSet` before Java 6 was `TreeSet`, which has been retrofitted with the methods required to implement the new interface `NavigableSet`. 

* This simplicity comes at a price, though:
** **merging `two sorted lists of size n is O(n)`, but** 
** **adding n elements to a `TreeSet` of size n is `O(n log n)`**.

* The methods defined by the `SortedSet` interface fall into **3 groups**:

** **Getting the First and Last Elements**
```
E first() // return the first element in the set
E last()  // return the last element in the set
//If the set is empty, these operations throw NoSuchElementException.
```
** **Retrieving the Comparator**

```
Comparator<? super E> comparator()
```
This method returns the set’s comparator if it has been given one at construction time. The type `Comparator<? super E>` is used because a `SortedSet` parameterized on `E` can rely for ordering on a Comparator defined on any supertype of `E`.
  
** **Getting Range Views**

```
SortedSet<E> subSet(E fromElement, E toElement) 
// containing every element of the original set
// that is greater than or equal to fromElement and less than toElement

SortedSet<E> headSet(E toElement)  // returns every element that is less than toElement

SortedSet<E> tailSet(E fromElement) // eturns every element that is greater than or equal to fromElement

```
[IMPORTANT]
====
Note that the arguments to these operations do not themselves have to be members of the set. The sets returned are half-open intervals: 

* they are inclusive of the fromElement—provided it actually is a set member, and 
* exclusive of the toElement.
====

---

=== NavigableSet

* `NavigableSet` was introduced in Java 6 to supplement deficiencies in `SortedSet`. 

```
public interface NavigableSet<E> extends SortedSet<E> {

    E lower(E e);
    E floor(E e);
    E ceiling(E e);
    E higher(E e);
    E pollFirst();
    E pollLast();

    Iterator<E> iterator();
    Iterator<E> descendingIterator();

    NavigableSet<E> descendingSet();
    NavigableSet<E> subSet(E fromElement, boolean fromInclusive, E toElement,   boolean toInclusive);
    NavigableSet<E> headSet(E toElement, boolean inclusive);
    NavigableSet<E> tailSet(E fromElement, boolean inclusive);

    SortedSet<E> subSet(E fromElement, E toElement);
    SortedSet<E> headSet(E toElement);
    SortedSet<E> tailSet(E fromElement);
}
```

* It **added methods in 4 group**:
+
--
1. **Getting the First and Last Elements**
These are analogous to the methods of the same name in `Deque`, and help to support the use of `NavigableSet` in applications which require queue functionality.
```
E pollFirst() // retrieve and remove the first (lowest) element,
              // or return null if this set is empty
E pollLast()  // retrieve and remove the last (highest) element,
              // or return null if this set is empty

```
[start=2]
2. **Getting Range Views**

*** This group is an **improvement on the methods of the same name in `SortedSet`.**
*** The `NavigableSet` methods, by contrast, allow to specify **for each bound whether it should be inclusive or exclusive**. 

```
NavigableSet<E> subSet(E fromElement, boolean fromInclusive,
                                      E toElement, boolean toInclusive)
NavigableSet<E> headSet(E toElement, boolean inclusive)
NavigableSet<E> tailSet(E fromElement, boolean inclusive)
```
[start=3]
3. **Getting Closest Matches**

```
E ceiling(E e) // return the least element in this set greater than
               // or equal to e, or null if there is no such element
E floor(E e)   // return the greatest element in this set less than
               // or equal to e, or null if there is no such element
E higher(E e)  // return the least element in this set strictly
               // greater than e, or null if there is no such element
E lower(E e)   // return the greatest element in this set strictly
               // less than e, or null if there is no such element

```

*** These methods are useful for short-distance navigation. 

[INPORTANT]
====
`NavigableSet` returns **null values to signify the absence of elements where**, 
for example, the first and last methods of `SortedSet` would `throw NoSuchElementException`. 

For this reason, should avoid `null` elements in `NavigableSets`.

In fact the newer implementation, `ConcurrentSkipListSet`, **does not permit them** **(though TreeSet must continue to do so, for backward compatibility)**.
====
[start=4]
4. **Navigating the Set in Reverse Order**

```
NavigableSet<E> descendingSet()   // return a reverse-order view of
                                  // the elements in this set
Iterator<E> descendingIterator()  // return a reverse-order iterator

```
--
---

=== TreeSet

* **Trees** are the data structure would choose for an application that needs:
  1. **fast insertion of individual elements**, 
  2. **retrieval of individual elements** and also
  3. **requires that they be held in sorted order**.

* In computing, a tree is a branching structure that represents hierarchy. Computing trees borrow a lot of their terminology from genealogical trees, though there are some differences; **the most important is that, in computing trees, each node has only one parent** (except the root, which has none). 
  
* An important class of tree often used in computing is a **binary tree** one in which each node can have at most two children.

image::collections/sets_image_3.png[An Ordered Balanced Binary Tree]

  * The most important property of this tree can be seen if you look at any nonleaf node—say, the one containing the word the: **all the nodes below that on the left contain words that precede the alphabetically**, and **all those on the right, words that follow it**. To locate a word, you would start at the root and descend level by level, doing an alphabetic comparison at each level, **so the cost of retrieving or inserting an element is proportional to the depth of the tree.**

* In general, **a binary tree with n complete levels will have 2n–1 elements**. Hence the depth of a tree with **n elements will be bounded by log n (since 2log n = n)**. 
  * Just as **n grows much more slowly than 2n, log n grows much more slowly than n**. 
  * So contains on a large tree is much faster than on a list containing the same elements. 
  * It’s still **not as good as on a hash table** whose operations can ideally work in constant time—but **a tree has the big advantage over a hash table that its iterator can return its elements in sorted order.**

* **Not all binary trees will have this nice performance**, below shows a balanced binary tree—one in which each node has an equal number of descendants (or as near as possible) on each side. **An unbalanced tree can give much worse performance—in the worst case, as bad as a linked list**. 

image::collections/sets_image_4.png[An Ordered Balanced Binary Tree]

* `TreeSet` **uses a data type called a red-black tree**, which has the advantage:
    * **if it becomes unbalanced through insertion or removal of an element, it can always be rebalanced in O(log n) time.**


* The constructors for `TreeSet` include, besides the standard ones, 
  * one which allows you to supply a `Comparator` and 
* one which allows you to create one from another `SortedSet`:

```
public class TreeSet<E> extends AbstractSet<E>
    implements NavigableSet<E>, Cloneable, java.io.Serializable
{
    /**
     * The backing map.
     */
    private transient NavigableMap<E,Object> m;

    // Dummy value to associate with an Object in the backing Map
    private static final Object PRESENT = new Object();

    /**
     * Constructs a set backed by the specified navigable map.
     */
    TreeSet(NavigableMap<E,Object> m) {
        this.m = m;
    }

    public TreeSet() {
        this(new TreeMap<>());
    }

    public TreeSet(Comparator<? super E> comparator) {
        this(new TreeMap<>(comparator));
    }

    public TreeSet(Collection<? extends E> c) {
        this();
        addAll(c);
    }

    public TreeSet(SortedSet<E> s) {
        this(s.comparator());
        addAll(s);
    }

    public Iterator<E> iterator() {
        return m.navigableKeySet().iterator();
    }

    public Iterator<E> descendingIterator() {
        return m.descendingKeySet().iterator();
    }

}

```
**`TreeSet` is unsychronized and not thread-safe; its iterators are fail-fast.**

---

=== ConcurrentSkipListSet

* `ConcurrentSkipListSet` was introduced in Java 6 as the first concurrent set implementation. 
* It is backed by a **skip list**, a modern alternative to the binary trees.
    
  * **A skip list for a set is a series of linked lists**, each of which is a chain of cells consisting of two fields: one to hold a value, and one to hold a reference to the next cell. Elements are inserted into and removed from a linked list in constant time by pointer rearrangement, as shown below.
  
image::collections/sets_image_5.png[Modifying a linked list]


The below  diagram shows a skip list consisting of three linked lists, labelled levels 0, 1 and 2. 
* The first linked list of the collection (level 0 in the figure) contains the elements of the set, sorted according to their natural order or by the comparator of the set. 
* Each list above level 0 contains a subset of the list below, chosen randomly according to a fixed probability. For this example, let’s suppose that the probability is 0.5; on average, each list will contain half the elements of the list below it. 
* Navigating between links takes a fixed time, so the quickest way to find an element is to start at the beginning (the left-hand end) of the top list and to go as far as possible on each list before dropping to the one below it.
* The curved arrows shows the progress of a search for the element 55. The search starts with the element 12 at the top left of level 2, steps to the element 31 on that level, then finds that the next element is 61, higher than the search value. So it drops one level, and then repeats the process; element 47 is still smaller than 55, but 61 is again too large, so it once more drops a level and finds the search value in one further step.


image::collections/sets_image_6.png[Searching a skip list]


Inserting an element into a skip list always involves at least inserting it at level 0. When that has been done, should it also be inserted at level 1? If level 1 contains, on average, half of the elements at level 0, then we should toss a coin (that is, randomly choose with probability 0.5) to decide whether it should be inserted at level 1 as well. If the coin toss does result in it being inserted at level 1, then the process is repeated for level 2, and so on. To remove an element from the skip list, it is removed from each level in which it occurs.

**The iterators of ConcurrentSkipListSet are weakly consistent.**

---

== Comparing Set Implementations
[%autowidth]
|===
|Sets                  | add      | contains | next     | notes

|HashSet               | O(1)     | O(1)     | O(h/n)   | h is the table capacity
|LinkedHashSet         | O(1)     | O(1)     | O(1)     | 
|CopyOnWriteArraySet   | O(n)     | O(n)     | O(1)     | 
|EnumSet               | O(1)     | O(1)     | O(1)     | 
|TreeSet               | O(log n) | O(log n) | O(log n) | 
|ConcurrentSkipListSet | O(log n) | O(log n) | O(1)     | 
|===

[IMPORTANT]
====
In the `EnumSet` implementation for `enum` types with more than 64 values, `next` has worst case complexity of `O(log m)`, where m is the number of elements in the enumeration.
====

Comparing Set Implementations
* `EnumSet` should always (and only) **be used to represent sets of enum**.  
* `CopyOnWriteArraySet` should only be used where 
  * `set` size will remain relatively small, 
  * read operations greatly outnumber writes, 
  * thread safety is required, and 
  * read-only iterators are acceptable.

That leaves the general-purpose implementations: 
  1. `HashSet`, 
  2. `LinkedHashSet`, 
  3. `TreeSet`, and 
  4. `ConcurrentSkipListSet`. 

  * The **first three are not thread-safe**, so can only be used in multi-threaded code either in conjunction with client-side locking, or wrapped in `Collection.synchronizedSet`. 
  * For single-threaded applications where there is **no requirement for the set to be sorted**, choice is between `HashSet` and `LinkedHashSet`. 
  * If application will be frequently iterating over the `set`, or require access **ordering**, `LinkedHashSet` is the implementation of choice.

  * Finally, if require the `set` **to sort its elements**, **the choice is between `TreeSet` and `ConcurrentSkipListSet`**. 
  * In a **multi-threaded environment**, `ConcurrentSkipListSet` is the only sensible choice. 
  * **Even in single-threaded code `ConcurrentSkipListSet` may not show a significantly worse performance for small set sizes**. 
  * For larger sets, or for applications **in which there are frequent element deletions**, `TreeSet` will perform better if application doesn’t require thread safety.