= Overview of the Set
:navtitle: Set
:description: 

{description}

Skip to Content
Search 50,000+ courses, events, titles, and more
Search 50,000+ courses, events, titles, and more
13. Sets
2h 12m remaining
Chapter 13. Sets
A set is a collection of items that cannot contain duplicates; adding an item if it is already present in the set has no effect. The Set interface has the same methods as those of Collection, but it is defined separately in order to allow the contract of add (and addAll, which is defined in terms of add) to be changed in this way. Returning to the task manager example in the previous chapter, suppose that on Monday you have free time to carry out your telephone tasks. You can make the appropriate collection by adding all your telephone tasks to your Monday tasks. Let mondayTasks and phoneTasks be as declared in Example 12-1. Using a set (again choosing a conveniently common implementation of Set), you can write:

Set<Task> phoneAndMondayTasks = new TreeSet<Task>(mondayTasks);
phoneAndMondayTasks.addAll(phoneTasks);
assert phoneAndMondayTasks.toString().equals(
  "[code logic, phone Mike, phone Paul]");
This works because of the way that duplicate elements are handled. The task mikePhone, which is in both mondayTasks and phoneTasks, appears as intended, only once, inphoneAndMondayTasks—you definitely don’t want to have to do all such tasks twice over!

Implementing Set
When we used the methods of Collection in the examples of Chapter 12, we emphasized that they would work with any implementation of Collection. What if we had decided that we would use one of the Set implementations from the Collections Framework? We would have had to choose between the various concrete implementations that the Framework provides, which differ both in how fast they perform the basic operations of add, contains, and iteration, and in the order in which their iterators return their elements. In this section and the next we will look at these differences, then at the end of the Chapter we will summarize the comparative performance of the different implementations.

There are six concrete implementations of Set in the Collections Framework. Figure 13-1 shows their relationship to Set and its subinterfaces SortedSet and NavigableSet. In this section, we will look at HashSet, LinkedHashSet, CopyOnWriteArraySet and EnumSet. We will discuss SortedSet and NavigableSet, together with their implementations, TreeSet and ConcurrentSkipListSet, in SortedSet and NavigableSet.

Implementations of the Set interface
Figure 13-1. Implementations of the Set interface
HashSet
This class is the most commonly used implementation of Set. As the name implies, it is implemented by a hash table, an array in which elements are stored at a position derived from their contents. Since hash tables store and retrieve elements by their content, they are well suited to implementing the operations of Set (the Collections Framework also uses them for various implementations of Map). For example, to implement contains(Object o) you would look for the element o and return true if it were found.

An element’s position in a hash table is calculated by a hash function of its contents. Hash functions are designed to give, as far as possible, an even spread of results (hash codes) over the element values that might be stored. For example, here is code like that used in the String class to calculate a hash code:

int hash = 0;
for (char ch : str.toCharArray()) {
  hash = hash * 31 + ch;
}
Traditionally, hash tables obtain an index from the hash code by taking the remainder after division by the table length. The Collections Framework classes actually use bit masking rather than division. Since that means it is the pattern of bits at the low end of the hash code that is significant, prime numbers (such as 31, here) are used in calculating the hash code because multiplying by primes will not tend to shift information away from the low end—as would multiplying by a power of 2, for example.

A moment’s thought will show that, unless your table has more locations than there are values that might be stored in it, sometimes two distinct values must hash to the same location in the hash table. For instance, no int-indexed table can be large enough to store all string values without collisions.We can minimize the problem with a good hash function—one which spreads the elements out equally in the table—but, when collisions do occur, we have to have a way of keeping the colliding elements at the same table location or bucket. This is often done by storing them in a linked list, as shown in Figure 13-2. We will look at linked lists in more detail as part of the implementations of ConcurrentSkipListSet (see ConcurrentSkipListSet) but, for now, it’s enough to see that elements stored at the same bucket can still be accessed, at the cost of following a chain of cell references. Figure 13-2 shows the situation resulting from running this code on Sun’s implementation of Java 5:

A hash table with chained overflow
Figure 13-2. A hash table with chained overflow
Set<Character> s1 = new HashSet<Character>(8);
s1.add('a');
s1.add('b');
s1.add('j');
The index values of the table elements have been calculated by using the bottom three bits (for a table of length 8) of the hash code of each element. In this implementation, a Character’s hash code is just the Unicode value of the character it contains. (In practice, of course, a hash table would be much bigger than this. Also, this diagram is simplified from the real situation; because HashSet is actually implemented by a specialized HashMap, each of the cells in the chain contains not one but two references, to a key and a value (see Chapter 16). Only the key is shown in this diagram because, when a hash table is being used to represent a set, all values are the same—only the presence of the key is significant.)

As long as there are no collisions, the cost of inserting or retrieving an element is constant. As the hash table fills, collisions become more likely; assuming a good hash function, the probability of a collision in a lightly loaded table is proportional to its load, defined as the number of elements in the table divided by its capacity (the number of buckets). If a collision does take place, a linked list has to be created and subsequently traversed, adding an extra cost to insertion proportional to the number of elements in the list. If the size of the hash table is fixed, performance will worsen as more elements are added and the load increases. To prevent this from happening, the table size is increased by rehashing—copying to a new and larger table—when the load reaches a specified threshold (its load factor).

Iterating over a hash table requires each bucket to be examined to see whether it is occupied and therefore costs a time proportional to the capacity of the hash table plus the number of elements it contains. Since the iterator examines each bucket in turn, the order in which elements are returned depends on their hash codes, so there is no guarantee as to the order in which the elements will be returned. The hash table shown in Figure 13-2 yields its elements in order of descending table index and forward traversal of the linked lists. Printing it produces the following output:

[j, b, a]
Later in this section we will look at LinkedHashSet, a variant of this implementation with an iterator that does return elements in their insertion order.

The chief attraction of a hash table implementation for sets is the (ideally) constant-time performance for the basic operations of add, remove, contains, and size. Its main disadvantage is its iteration performance; since iterating through the table involves examining every bucket, its cost is proportional to the table size regardless of the size of the set it contains.

HashSet has the standard constructors that we introduced in Collection Constructors, together with two additional constructors:

HashSet(int initialCapacity)
HashSet(int initialCapacity, float loadFactor)
Both of these constructors create an empty set but allow some control over the size of the underlying table, creating one with a length of the next-largest power of 2 after the supplied capacity. Most of the hash table–based implementations in the Collections Framework have similar constructors, although Joshua Bloch, the original designer of the Framework, has told us that new classes will no longer usually have configuration parameters like the load factor; they are not generally useful, and they limit the possibilities of improving implementations at a later date.

HashSet is unsychronized and not thread-safe; its iterators are fail-fast.

LinkedHashSet
This class inherits from HashSet, still implementing Set and refining the contract of its superclass in only one respect: it guarantees that its iterators will return their elements in the order in which they were first added. It does this by maintaining a linked list of the set elements, as shown by the curved arrows in Figure 13-3. The situation in the figure would result from this code:

Set<Character> s2 = new LinkedHashSet<Character>(8);
Collections.addAll(s2, 'a', 'b', 'j');
// iterators of a LinkedHashSet return their elements in proper order:
assert s2.toString().equals("[a, b, j]");
A linked hash table
Figure 13-3. A linked hash table
The linked structure also has a useful consequence in terms of improved performance for iteration: next performs in constant time, as the linked list can be used to visit each element in turn. This is in contrast to HashSet, for which every bucket in the hash table must be visited whether it is occupied or not, but the overhead involved in maintaining the linked list means that you would choose LinkedHashSet in preference to HashSet only if the orde or the efficiency of iteration were important for your application.

The constructors for LinkedHashSet provide the same facilities as those of HashSet for configuring the underlying hash table. Like HashSet, it is unsychronized and not thread-safe; its iterators are fail-fast.

CopyOnWriteArraySet
In functional terms, CopyOnWriteArraySet is another straightforward implementation of the Set contract, but with quite different performance characteristics from HashSet. This class is implemented as a thin wrapper around an instance of CopyOnWriteArrayList, which in turn is backed by an array. This array is treated as immutable; a change to the contents of the set results in an entirely new array being created. So add has complexity O(n), as does contains, which has to be implemented by a linear search. Clearly you wouldn’t use CopyOnWriteArraySet in a context where you were expecting many searches or insertions. But the array implementation means that iteration costs O(1) per element—faster than HashSet—and it has one advantage which is really compelling in some applications: it provides thread safety (see Collections and Thread Safety) without adding to the cost of read operations. This is in contrast to those collections which use locking to achieve thread safety for all operations (for example, the synchronized collections of Synchronized Collections). Such collections are a bottleneck in multi-threaded use because a thread must get exclusive access to the collection object before it can use it in any way. By contrast, read operations on copy-on-write collections are implemented on the backing array, which is never modified after its creation, so they can be used by any thread without danger of interference from a concurrent write operation.

When would you want to use a set with these characteristics? In fairly specialized cases; one that is quite common is in the implementation of the Subject-Observer design pattern (see Subject-Observer), which requires events to be notified to a set of observers. This set must not be modified during the process of notification; with locking set implementations, read and write operations share the overhead necessary to ensure this, whereas with CopyOnWriteArraySet the overhead is carried entirely by write operations. This makes sense for Subject-Observer; in typical uses of this pattern, event notifications occur much more frequently than changes to the listener set.

Iterators for CopyOnWriteArraySet can be used only to read the set. When they are created, they are attached to the instance of the backing array being used by the set at that moment. Since no instance of this array should ever be modified, the iterators’ remove method is not implemented. These are snapshot iterators (see Collections and Thread Safety); they reflect the state of the set at the time they were created, and can subsequently be traversed without any danger of interference from threads modifying the set from which they were derived.

Since there are no configuration parameters for CopyOnWriteArraySet, the constructors are just the standard ones discussed in Collection Constructors.

EnumSet
This class exists to take advantage of the efficient implementations that are possible when the number of possible elements is fixed and a unique index can be assigned to each. These two conditions hold for a set of elements of the same Enum; the number of keys is fixed by the constants of the enumerated type, and the ordinal method returns values that are guaranteed to be unique to each constant. In addition, the values that ordinal returns form a compact range, starting from zero—ideal, in fact, for use as array indices or, in the standard implementation, indices of a bit vector. So add, remove, and contains are implemented as bit manipulations, with constant-time performance. Bit manipulation on a single word is extremely fast, and a long value can be used to represent EnumSets over enum types with up to 64 values. Larger enums can be treated in a similar way, with some overhead, using more than one word for the representation.

EnumSet is an abstract class that implements these different representations by means of different package-private subclasses. It hides the concrete implementation from the programmer, instead exposing factory methods that call the constructor for the appropriate subclass. The following group of factory methods provide ways of creating EnumSets with different initial contents: empty, specified elements only, or all elements of the enum.

<E extends Enum<E>> EnumSet<E> of(E first, E... rest)
        // create a set initially containing the specified elements
<E extends Enum<E>> EnumSet<E> range(E from, E to)
        // create a set initially containing all of the elements in
        // the range defined by the two specified endpoints
<E extends Enum<E>> EnumSet<E> allOf(Class<E> elementType)
        // create a set initially containing all elements in elementType
<E extends Enum<E>> EnumSet<E> noneOf(Class<E> elementType)
        // create a set of elementType, initially empty
An EnumSet contains the reified type of its elements, which is used at run time for checking the validity of new entries. This type is supplied by the above factory methods in two different ways. The methods of and range receive at least one enum argument, which can be queried for its declaring class (that is, the Enum that it belongs to). For allOf and noneOf, which have no enum arguments, a class token is supplied instead.

Common cases for EnumSet creation are optimized by the second group of methods, which allow you to efficiently create sets with one, two, three, four, or five elements of an enumerated type.

<E extends Enum<E>> EnumSet<E> of(E e)
<E extends Enum<E>> EnumSet<E> of(E e1, E e2)
<E extends Enum<E>> EnumSet<E> of(E e1, E e2, E e3)
<E extends Enum<E>> EnumSet<E> of(E e1, E e2, E e3, E e4)
<E extends Enum<E>> EnumSet<E> of(E e1, E e2, E e3, E e4, E e5)
The third set of methods allows the creation of an EnumSet from an existing collection:

<E extends Enum<E>> EnumSet<E> copyOf(EnumSet<E> s)
      // create an EnumSet with the same element type as s, and
      // with the same elements
<E extends Enum<E>> EnumSet<E> copyOf(Collection<E> c)
      // create an EnumSet from the elements of c, which must contain
      // at least one element
<E extends Enum<E>> EnumSet<E> complementOf(EnumSet<E> s)
      // create an EnumSet with the same element type as s,
      // containing the elements not in s
The collection supplied as the argument to the second version of copyOf must be nonempty so that the element type can be determined.

In use, EnumSet obeys the contract for Set, with the added specification that its iterators will return their elements in their natural order (the order in which their enum constants are declared). It is not thread-safe, but unlike the unsynchronized general-purpose collections, its iterators are not fail-fast. They may be either snapshot or weakly consistent; to be conservative, the contract guarantees only that they will be weakly consistent (see Collections and Thread Safety).

SortedSet
Figure 13-4. SortedSet
SortedSet and NavigableSet
Set has one subinterface, SortedSet (Figure 13-4), which adds to the Set contract a guarantee that its iterator will traverse the set in ascending element order. SortedSet was itself extended in Java 6 by the interface NavigableSet (see Figure 13-5), which adds methods to find the closest matches to a target element. The only implementation of SortedSet before Java 6was TreeSet, which has been retrofitted with the methods required to implement the new interface. Since there is no platform implementation of SortedSet in Java 6 that does not also implement NavigableSet, it makes sense to discuss them in the same section. For new client code developed for the Java 6 platform, there is no need to use the SortedSet interface at all, but for the benefit of readers still constrained to use Java 5 we shall present the methods of the two interfaces separately in this section.

In Chapter 3 we saw that element ordering can either be defined by the element class itself, if that implements Comparable, or it can be imposed by an external Comparator, supplied by a constructor such as this one, for TreeSet:

TreeSet(Comparator<? super E> comparator)
Task does implement Comparable (its natural ordering is the natural ordering of its string representation), so we don’t need to supply a separate comparator. Now merging two ordered lists, which was quite tricky using parallel iterators, is trivial if we get a SortedSet to do the work. Using the task collections of Example 12-1, it requires two lines of code:

Set<Task> naturallyOrderedTasks = new TreeSet<Task>(mondayTasks);
naturallyOrderedTasks.addAll(tuesdayTasks);
assert naturallyOrderedTasks.toString().equals (
  "[code db, code gui, code logic, phone Mike, phone Paul]");
This simplicity comes at a price, though; merging two sorted lists of size n is O(n), but adding n elements to a TreeSet of size n is O(n log n).

We could use SortedSet to add some function to the to-do manager. Until now, the methods of Collection and Set have given us no help in ordering our tasks—surely one of the central requirements of a to-do manager. Example 13-1 defines a class PriorityTask which attaches a priority to a task. There are three priorities, HIGH, MEDIUM, and LOW, declared so that HIGH priority comes first in the natural ordering. To compare two PriorityTasks, we first compare their priorities; if the priorities are unequal, the higher priority tasks comes first, and if the priorities are equal, we use the natural ordering on the underlying tasks. To test whether two PriorityTasks are equal, we check whether they have the same priority and the same task. These definitions ensure that the natural ordering is consistent with equals (see Comparable). As when we defined tasks in Using the Methods of Collection, we have followed good practice by making PriorityTask immutable.

Example 13-1. The class PriorityTask
public enum Priority { HIGH, MEDIUM, LOW }
public final class PriorityTask implements Comparable<PriorityTask> {
  private final Task task;
  private final Priority priority;
  PriorityTask(Task task, Priority priority) {
    this.task = task;
    this.priority = priority;
  }
  public Task getTask() { return task; }
  public Priority getPriority() { return priority; }
  public int compareTo(PriorityTask pt) {
    int c = priority.compareTo(pt.priority);
    return c != 0 ? c : task.compareTo(pt.task);
  }
  public boolean equals(Object o) {
    if (o instanceof PriorityTask) {
      PriorityTask pt = (PriorityTask)o;
      return task.equals(pt.task) && priority.equals(pt.priority);
    } else return false;
  }
  public int hashCode() { return task.hashCode(); }
  public String toString() { return task + ": " + priority; }
}
The following code shows SortedSet working with a set of PriorityTasks (in fact, we have declared a NavigableSet so that we can use the same set in later examples. But for the moment, we will just use the methods of SortedSet):

NavigableSet<PriorityTask> priorityTasks = new TreeSet<PriorityTask>();
priorityTasks.add(new PriorityTask(mikePhone, Priority.MEDIUM));
priorityTasks.add(new PriorityTask(paulPhone, Priority.HIGH));
priorityTasks.add(new PriorityTask(databaseCode, Priority.MEDIUM));
priorityTasks.add(new PriorityTask(interfaceCode, Priority.LOW));

assert(priorityTasks.toString()).equals(
  "[phone Paul: HIGH, code db: MEDIUM, phone Mike: MEDIUM, code gui: LOW]");
Could you not simply compare the priorities of the tasks, without using the string representation as a secondary key? A partial ordering like that would be useful if you want to preserve some aspects of the original ordering; for example, you might wish to sort tasks by priority but, within each priority, preserve the order in which they were added to the set. But the contract for SortedSet (and, as we shall see later, SortedMap) states that it will use the compare method of its Comparator—or, if it does not have one, the compareTo method of its elements—instead of the elements’ equals method to determine when elements are distinct. This means that if a number of elements compare as the same, the set will treat them as duplicates, and all but one will be discarded.

The methods defined by the SortedSet interface fall into three groups:

Getting the First and Last Elements

E first() // return the first element in the set
E last()  // return the last element in the set
If the set is empty, these operations throw NoSuchElementException.

Retrieving the Comparator

Comparator<? super E> comparator()
This method returns the set’s comparator if it has been given one at construction time. The type Comparator<? super E> is used because a SortedSet parameterized on E can rely for ordering on a Comparator defined on any supertype of E. For example, recalling A Fruity Example, a Comparator<Fruit> could be used with a SortedSet<Apple>.

Getting Range Views

SortedSet<E> subSet(E fromElement, E toElement)
SortedSet<E> headSet(E toElement)
SortedSet<E> tailSet(E fromElement)
The method subSet returns a set containing every element of the original set that is greater than or equal to fromElement and less than toElement. Similarly, the method headset returns every element that is less than toElement, and tailSet returns every element that is greater than or equal to fromElement. Note that the arguments to these operations do not themselves have to be members of the set. The sets returned are half-open intervals: they are inclusive of the fromElement—provided it actually is a set member, of course—and exclusive of the toElement.

In our example, these methods could be useful in providing different views of the elements in priorityTasks. For instance, we can use headSet to obtain a view of the high- and medium-priority tasks. To do this, we need a special task that comes before all others in the task ordering; fortunately, we defined a class EmptyTask for just this purpose in Using the Methods of Collection. Using this, it is easy to extract all tasks that come before any low-priority task:

PriorityTask firstLowPriorityTask =
  new PriorityTask(new EmptyTask(), Priority.LOW);
SortedSet<PriorityTask> highAndMediumPriorityTasks =
  priorityTasks.headSet(firstLowPriorityTask);
assert highAndMediumPriorityTasks.toString().equals(
  "[phone Paul: HIGH, code db: MEDIUM, phone Mike: MEDIUM]");
In fact, because we know that tasks with empty details will never normally occur, we can also use one as the first endpoint in a half-open interval:

PriorityTask firstMediumPriorityTask =
  new PriorityTask(new EmptyTask(), Priority.MEDIUM);
SortedSet<PriorityTask> mediumPriorityTasks =
  priorityTasks.subSet(
    firstMediumPriorityTask, firstLowPriorityTask);
assert mediumPriorityTasks.toString().equals(
  "[code db: MEDIUM, phone Mike: MEDIUM]");
Not all orderings can be treated so conveniently; suppose, for example, that we want to work with the set of all the medium-priority tasks up to and including the mikePhone task. To define that set as a half-open interval, users of SortedSet would need to construct the task that immediately follows the mikePhone task in the PriorityTask ordering, and for that you would need to know that the string that succeeds "Mike" in the natural ordering is "Mike\0" (that is, "Mike" with a null character appended). Fortunately, users of NavigableSet have a much more intuitive way of defining this set, as we shall see in a moment.

Notice that the sets returned by these operations are not independent sets but new views of the original SortedSet. So we can add elements to the original set and see the changes reflected in the view:

PriorityTask logicCodeMedium =
  new PriorityTask(logicCode, Priority.MEDIUM);
priorityTasks.add(logicCodeMedium);
assert mediumPriorityTasks.toString().equals(
  "[code db: MEDIUM, code logic: MEDIUM, phone Mike: MEDIUM]");
The reverse applies also; changes in the view are reflected in the original set:

mediumPriorityTasks.remove(logicCodeMedium);
assert priorityTasks.toString().equals(
  "[phone Paul: HIGH, code db: MEDIUM, phone Mike: MEDIUM, code gui: LOW]");
To understand how this works, think of all the possible values in an ordering as lying on a line, like the number line used in arithmetic. A range is defined as a fixed segment of that line, regardless of which values are actually in the original set. So a subset, defined on a SortedSet and a range, will allow you to work with whichever elements of the SortedSet currently lie within the range.

NavigableSet
Figure 13-5. NavigableSet
NavigableSet
NavigableSet (see Figure 13-5) was introduced in Java 6 to supplement deficiencies in SortedSet. As we mentioned at the beginning of this section, new client code should use it in preference to SortedSet. It adds methods in four groups.

Getting the First and Last Elements

E pollFirst() // retrieve and remove the first (lowest) element,
              // or return null if this set is empty
E pollLast()  // retrieve and remove the last (highest) element,
              // or return null if this set is empty
These are analogous to the methods of the same name in Deque (see Deque), and help to support the use of NavigableSet in applications which require queue functionality. For example, in the version of the to-do manager in this section, we could get the highest-priority task off the list, ready to be carried out, by means of this:

PriorityTask nextTask = priorityTasks.pollFirst();
assert nextTask.toString().equals("phone Paul: HIGH");
Notice that although Deque also contains methods peekFirst and peekLast—which allow clients to retrieve an element without removing it—NavigableSet has no need of them, because their functions are already supplied by the methods first and last inherited from SortedSet.

Getting Range Views

NavigableSet<E> subSet(E fromElement, boolean fromInclusive,
                                      E toElement, boolean toInclusive)
NavigableSet<E> headSet(E toElement, boolean inclusive)
NavigableSet<E> tailSet(E fromElement, boolean inclusive)
This group is an improvement on the methods of the same name in SortedSet, which return subsets that are always inclusive of the lower bound and exclusive of the higher one. The NavigableSet methods, by contrast, allow you to specify for each bound whether it should be inclusive or exclusive. This makes it much easier to define range views over some sets. We considered earlier the set containing all the medium-priority tasks up to and including the (medium-prioritized) mikePhone task. To obtain that set using SortedSet, we would have to define it as a half-open interval, using a little-known technicality of string ordering. But NavigableSet allows us to define it as a closed interval simply by specifying that the higher bound should be inclusive:

PriorityTask mikePhoneMedium = new PriorityTask(mikePhone, Priority.MEDIUM);
NavigableSet closedInterval = priorityTasks.subSet(
  firstMediumPriorityTask, true, mikePhoneMedium, true);
assert(closedInterval.toString()).equals(
  "[code db: MEDIUM, phone Mike: MEDIUM]");
Getting Closest Matches

E ceiling(E e) // return the least element in this set greater than
               // or equal to e, or null if there is no such element
E floor(E e)   // return the greatest element in this set less than
               // or equal to e, or null if there is no such element
E higher(E e)  // return the least element in this set strictly
               // greater than e, or null if there is no such element
E lower(E e)   // return the greatest element in this set strictly
               // less than e, or null if there is no such element
These methods are useful for short-distance navigation. For example, suppose that we want to find, in a sorted set of strings, the last three strings in the subset that is bounded above by “x-ray”, including that string itself if it is present in the set. NavigableSet methods make this easy:

NavigableSet<String> stringSet = new TreeSet<String>();
Collections.addAll(stringSet, "abc", "cde", "x-ray" ,"zed");
String last = stringSet.floor("x-ray");
assert last.equals("x-ray");
String secondToLast =
  last == null ? null : stringSet.lower(last);
String thirdToLast =

  secondToLast == null ? null : stringSet.lower(secondToLast);
assert thirdToLast.equals("abc");
Notice that in line with a general trend in the design of the Collections Framework, NavigableSet returns null values to signify the absence of elements where, for example, the first and last methods of SortedSet would throw NoSuchElementException. For this reason, you should avoid null elements in NavigableSets, and in fact the newer implementation, ConcurrentSkipListSet, does not permit them (though TreeSet must continue to do so, for backward compatibility).

Navigating the Set in Reverse Order

NavigableSet<E> descendingSet()   // return a reverse-order view of
                                  // the elements in this set
Iterator<E> descendingIterator()  // return a reverse-order iterator
Methods of this group make traversing a NavigableSet equally easy in the descending (that is, reverse) ordering. As a simple illustration, let’s generalise the example above using the nearest-match methods. Suppose that, instead of finding just the last three strings in the sorted set bounded above by “x-ray”, we want to iterate over all the strings in that set, in descending order:

NavigableSet<String> headSet = stringSet.headSet(last, true);
NavigableSet<String> reverseHeadSet = headSet.descendingSet();
assert reverseHeadSet.toString().equals("[x-ray, cde, abc]");
String conc = " ";
for (String s : reverseHeadSet) {
  conc += s + " ";
}
assert conc.equals(" x-ray cde abc ");
If the iterative processing involves structural changes to the set, and the implementation being used is TreeSet (which has fail-fast iterators), we will have to use an explicit iterator to avoid ConcurrentModificationException:

for (Iterator<String> itr = headSet.descendingIterator(); itr.hasNext(); ) {
  itr.next(); itr.remove();
}
assert headSet.isempty();
TreeSet
This is the first tree implementation that we have seen, so we should take a little time now to consider how trees perform in comparison to the other implementation types used by the Collections Framework.

Trees are the data structure you would choose for an application that needs fast insertion and retrieval of individual elements but which also requires that they be held in sorted order.

An ordered, balanced binary tree
Figure 13-6. An ordered, balanced binary tree
For example, suppose you want to match all the words from a set against a given prefix, a common requirement in visual applications where a drop-down should ideally show all the possible elements that match against the prefix that the user has typed. A hash table can’t return its elements in sorted order and a list can’t retrieve its elements quickly by their content, but a tree can do both.

In computing, a tree is a branching structure that represents hierarchy. Computing trees borrowa lot of their terminology from genealogical trees, though there are some differences; the most important is that, in computing trees, each node has only one parent (except the root, which has none). An important class of tree often used in computing is a binary tree—one in which each node can have at most two children. Figure 13-6 shows an example of a binary tree containing the words of this sentence in alphabetical order.

The most important property of this tree can be seen if you look at any nonleaf node—say, the one containing the word the: all the nodes below that on the left contain words that precede the alphabetically, and all those on the right, words that follow it. To locate a word, you would start at the root and descend level by level, doing an alphabetic comparison at each level, so the cost of retrieving or inserting an element is proportional to the depth of the tree.

How deep, then, is a tree that contains n elements? The complete binary tree with two levels has three elements (that’s 22–1), and the one with three levels has seven elements (23–1). In general, a binary tree with n complete levels will have 2n–1 elements. Hence the depth of a tree with n elements will be bounded by log n (since 2log n = n). Just as n grows much more slowly than 2n, log n grows much more slowly than n. So contains on a large tree is much faster than on a list containing the same elements. It’s still not as good as on a hash table—whose operations can ideally work in constant time—but a tree has the big advantage over a hash table that its iterator can return its elements in sorted order.

Not all binary trees will have this nice performance, though. Figure 13-6 shows a balanced binary tree—one in which each node has an equal number of descendants (or as near as possible) on each side. An unbalanced tree can give much worse performance—in the worst case, as bad as a linked list (see Figure 13-7). TreeSet uses a data type called a red-black tree, which has the advantage that if it becomes unbalanced through insertion or removal of an element, it can always be rebalanced in O(log n) time.

An unbalanced binary tree
Figure 13-7. An unbalanced binary tree
The constructors for TreeSet include, besides the standard ones, one which allows you to supply a Comparator (see Comparator) and one which allows you to create one from another SortedSet:

TreeSet(Comparator<? super E> c)
              // construct an empty set which will be sorted using the
              // specified comparator
TreeSet(SortedSet<E> s)
              // construct a new set containing the elements of the
              // supplied set, sorted according to the same ordering
The second of these is rather too close in its declaration to the standard "conversion constructor” (see Collection Constructors):

TreeSet(Collection<? extends E> c)
As Joshua Bloch explains in Effective Java (item “Use overloading judiciously” in the chapter on Methods), calling one of two constructor or method overloads which take parameters of related type can give confusing results. This is because, in Java, calls to overloaded constructors and methods are resolved at compile time on the basis of the static type of the argument, so applying a cast to an argument can make a big difference to the result of the call, as the following code shows:

// construct and populate a NavigableSet whose iterator returns its
// elements in the reverse of natural order:
NavigableSet<String> base = new TreeSet<String>(Collections.reverseOrder());
Collections.addAll(base, "b", "a", "c");

// call the two different constructors for TreeSet, supplying the
// set just constructed, but with different static types:
NavigableSet<String> sortedSet1 = new TreeSet<String>((Set<String>)base);
NavigableSet<String> sortedSet2 = new TreeSet<String>(base);
// and the two sets have different iteration orders:
List<String> forward = new ArrayList<String>();
forward.addAll(sortedSet1);
List<String> backward = new ArrayList<String>();
backward.addAll(sortedSet2);
assert !forward.equals(backward);
Collections.reverse(forward);
assert forward.equals(backward);
This problem afflicts the constructors for all the sorted collections in the Framework (TreeSet, TreeMap, ConcurrentSkipListSet, and ConcurrentSkipListMap). To avoid it in your own class designs, choose parameter types for different overloads so that an argument of a type appropriate to one overload cannot be cast to the type appropriate to a different one. If that is not possible, the two overloads should be designed to behave identically with the same argument, regardless of its static type. For example, a PriorityQueue (PriorityQueue) constructed from a collection uses the ordering of the original, whether the static type with which the constructor is supplied is one of the Comparator-containing types PriorityQueue or SortedSet, or just a plain Collection. To achieve this, the conversion constructor uses the Comparator of the supplied collection, only falling back on natural ordering if it does not have one.

TreeSet is unsychronized and not thread-safe; its iterators are fail-fast.

ConcurrentSkipListSet
ConcurrentSkipListSet was introduced in Java 6 as the first concurrent set implementation. It is backed by a skip list, a modern alternative to the binary trees of the previous section. A skip list for a set is a series of linked lists, each of which is a chain of cells consisting of two fields: one to hold a value, and one to hold a reference to the next cell. Elements are inserted into and removed from a linked list in constant time by pointer rearrangement, as shown in Figure 13-8, parts (a) and (b) respectively.

Modifying a linked list
Figure 13-8. Modifying a linked list
Searching a skip list
Figure 13-9. Searching a skip list
Figure 13-9 shows a skip list consisting of three linked lists, labelled levels 0, 1 and 2. The first linked list of the collection (level 0 in the figure) contains the elements of the set, sorted according to their natural order or by the comparator of the set. Each list above level 0 contains a subset of the list below, chosen randomly according to a fixed probability. For this example, let’s suppose that the probability is 0.5; on average, each list will contain half the elements of the list below it. Navigating between links takes a fixed time, so the quickest way to find an element is to start at the beginning (the left-hand end) of the top list and to go as far as possible on each list before dropping to the one below it.

The curved arrows of Figure 13-9 shows the progress of a search for the element 55. The search starts with the element 12 at the top left of level 2, steps to the element 31 on that level, then finds that the next element is 61, higher than the search value. So it drops one level, and then repeats the process; element 47 is still smaller than 55, but 61 is again too large, so it once more drops a level and finds the search value in one further step.

Inserting an element into a skip list always involves at least inserting it at level 0. When that has been done, should it also be inserted at level 1? If level 1 contains, on average, half of the elements at level 0, then we should toss a coin (that is, randomly choose with probability 0.5) to decide whether it should be inserted at level 1 as well. If the coin toss does result in it being inserted at level 1, then the process is repeated for level 2, and so on. To remove an element from the skip list, it is removed from each level in which it occurs.

If the coin tossing goes badly, we could end up with every list above level 0 empty—or full, which would be just as bad. These outcomes have very low probability, however, and analysis shows that, in fact, the probability is very high that skip lists will give performance comparable to binary trees: search, insertion and removal all take O(log n). Their compelling advantage for concurrent use is that they have efficient lock-free insertion and deletion algorithms, whereas there are none known for binary trees.

The iterators of ConcurrentSkipListSet are weakly consistent.

Table 13-1. Comparative performance of different Set implementations
 	
add

contains

next

notes

HashSet

O(1)

O(1)

O(h/n)

h is the table capacity

LinkedHashSet

O(1)

O(1)

O(1)

 
CopyOnWriteArraySet

O(n)

O(n)

O(1)

 
EnumSet

O(1)

O(1)

O(1)

 
TreeSet

O(log n)

O(log n)

O(log n)

 
ConcurrentSkipListSet

O(log n)

O(log n)

O(1)

 
* In the EnumSet implementation for enum types with more than 64 values, next has worst case complexity of O(log m), where m is the number of elements in the enumeration.

Comparing Set Implementations
Table 13-1 shows the comparative performance of the different Set implementations. When you are choosing an implementation, of course, efficiency is only one of the factors you should take into account. Some of these implementations are specialized for specific situations; for example, EnumSet should always (and only) be used to represent sets of enum. Similarly, CopyOnWriteArraySet should only be used where set size will remain relatively small, read operations greatly outnumber writes, thread safety is required, and read-only iterators are acceptable.

That leaves the general-purpose implementations: HashSet, LinkedHashSet, TreeSet, and ConcurrentSkipListSet. The first three are not thread-safe, so can only be used in multi-threaded code either in conjunction with client-side locking, or wrapped in Collection.synchronizedSet (see Synchronized Collections). For single-threaded applications where there is no requirement for the set to be sorted, your choice is between HashSet and LinkedHashSet. If your application will be frequently iterating over the set, or if you require access ordering, LinkedHashSet is the implementation of choice.

Finally, if you require the set to sort its elements, the choice is between TreeSet and ConcurrentSkipListSet. In a multi-threaded environment, ConcurrentSkipListSet is the only sensible choice. Even in single-threaded code ConcurrentSkipListSet may not show a significantly worse performance for small set sizes. For larger sets, however, or for applications in which there are frequent element deletions, TreeSet will perform better if your application doesn’t require thread safety.

table of contents
search
Settings
queue